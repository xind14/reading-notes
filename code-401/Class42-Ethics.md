# Read 42: Ethics

## Submission Requirements

Below is a collection of resources of varying types and lengths which describe the topics for the upcoming lecture.

Create a new page in your reading-notes repo with your reflections.

Review at least one article from both “Ethics in the workplace” and “Ethics in Technology” sections below and write how each of them relates to ethics in technology. Do you agree or disagree with these articles? What stuck out to you specifically from each article?

For each article that you choose, write a minimum 5 sentences (1 paragraph). Each reflection should be something of substance and of an acceptable quality.

## Readings/Resources/Links

- chatgpt

### Code of Ethics

1. Skim: [Code of Ethics](https://www.acm.org/code-of-ethics)

   - GENERAL ETHICAL PRINCIPLES. _A computing professional should..._
     - Contribute to society and to human well-being, acknowledging that all people are stakeholders in computing.
     - Avoid harm.
     - Be honest and trustworthy.
     - Be fair and take action not to discriminate.
     - Respect the work required to produce new ideas, inventions, creative works, and computing artifacts.
     - Respect privacy.
     - Honor confidentiality.
   - PROFESSIONAL RESPONSIBILITIES.
     - Strive to achieve high quality in both the processes and products of professional work.
     - Maintain high standards of professional competence, conduct, and ethical practice.
     - Know and respect existing rules pertaining to professional work.
     - Accept and provide appropriate professional review.
     - Give comprehensive and thorough evaluations of computer systems and their impacts, including analysis of possible risks.
     - Perform work only in areas of competence.
     - Foster public awareness and understanding of computing, related technologies, and their consequences.
     - Access computing and communication resources only when authorized or when compelled by the public good.
     - Design and implement systems that are robustly and usably secure.
   - PROFESSIONAL LEADERSHIP PRINCIPLES.
     - Ensure that the public good is the central concern during all professional computing work.
     - Articulate, encourage acceptance of, and evaluate fulfillment of social responsibilities by members of the organization or group.
     - Manage personnel and resources to enhance the quality of working life.
     - Articulate, apply, and support policies and processes that reflect the principles of the Code.
     - Create opportunities for members of the organization or group to grow as professionals.
     - Use care when modifying or retiring systems.
     - Recognize and take special care of systems that become integrated into the infrastructure of society.

2. Skim: [Software Engineering Code of Ethics](https://ethics.acm.org/code-of-ethics/software-engineering-code/)

   - PUBLIC – Software engineers shall act consistently with the public interest.
   - CLIENT AND EMPLOYER – Software engineers shall act in a manner that is in the best interests of their client and employer consistent with the public interest.
   - PRODUCT – Software engineers shall ensure that their products and related modifications meet the highest professional standards possible.
   - JUDGMENT – Software engineers shall maintain integrity and independence in their professional judgment.
   - MANAGEMENT – Software engineering managers and leaders shall subscribe to and promote an ethical approach to the management of software development and maintenance.
   - PROFESSION – Software engineers shall advance the integrity and reputation of the profession consistent with the public interest.
   - COLLEAGUES – Software engineers shall be fair to and supportive of their colleagues.
   - SELF – Software engineers shall participate in lifelong learning regarding the practice of their profession and shall promote an ethical approach to the practice of the profession.

### Ethics in the workplace

1. [The code I’m still ashamed of](https://medium.freecodecamp.org/the-code-im-still-ashamed-of-e4c021dff55e)

   - "As developers, we are often one of the last lines of defense against potentially dangerous and unethical practices. We’re approaching a time where software will drive the vehicle that transports your family to soccer practice. There are already AI programs that help doctors diagnose disease. It’s not hard to imagine them recommending prescription drugs soon, too. The more software continues to take over every aspect of our lives, the more important it will be for us to take a stand and ensure that our ethics are ever-present in our code. Since that day, I always try to think twice about the effects of my code before I write it. I hope that you will too."

2. [Project Dragonfly, Google’s censored search engine](https://www.vox.com/2018/8/17/17704526/google-dragonfly-censored-search-engine-china)
3. [Amazon workers demand Jeff Bezos cancel “Recognition” software](https://gizmodo.com/amazon-workers-demand-jeff-bezos-cancel-face-recognitio-1827037509)
4. [Google and AI](https://gizmodo.com/in-reversal-google-says-its-ai-will-not-be-used-for-we-1826649327)
5. [Microsoft Employees demand end of ICE contract](https://web.archive.org/web/20211124172013/https://www.nytimes.com/2018/06/19/technology/tech-companies-immigration-border.html)
6. [Microsoft and the DoD](https://web.archive.org/web/20200616232735/https://www.businessinsider.com/microsoft-employees-protest-contract-us-army-hololens-2019-2)

### Ethics in Technology

1. [Self Driving Car Ethics](https://www.freep.com/story/money/cars/2017/11/21/self-driving-cars-ethics/804805001/)

   - Who dies when the car is forced into a no-win situation?
   - to avoid accidents, but that “If it happens where there is a situation where a car couldn’t escape, it’ll go for the smaller thing.”

2. [Ethical dilemma of self driving cars](https://www.theglobeandmail.com/globe-drive/culture/technology/the-ethical-dilemmas-of-self-drivingcars/article37803470/)

   - We need to program that intelligence into a vehicle, but we don't have the data yet to create a machine that can perceive and respond to the virtually endless permutations of near misses and random occurrences that happen on even a simple trip to the corner store."

3. [Cyber-Security of self driving cars](https://phys.org/news/2017-02-cybersecurity-self-driving-cars.html)
4. [Big Data is our Civil Rights issue](http://solveforinteresting.com/big-data-is-our-generations-civil-rights-issue-and-we-dont-know-it/)
5. [Will democracy survive big data and AI?](https://www.scientificamerican.com/article/will-democracy-survive-big-data-and-artificial-intelligence/)

### Tech Company Principles

1. [Microsoft AI Principles](https://www.microsoft.com/en-us/AI/our-approach-to-ai)
2. [Ethical OS Toolkit](https://ethicalos.org/)
3. [Google AI Principles](https://www.blog.google/technology/ai/ai-principles/)

### Reading Answers

> [The code I’m still ashamed of](https://medium.freecodecamp.org/the-code-im-still-ashamed-of-e4c021dff55e)

This reading vividly exposes the ethical conflicts that can emerge in the realm of technology. The scenario of designing a quiz on a pharmaceutical website, which indirectly promotes a specific drug without transparency, touches on ethical considerations in coding practices. It highlights the responsibility of developers to critically engage with the consequences of their work, especially in sensitive areas like healthcare. This anecdote highlights the necessity for ethical awareness and moral reflection in the technology industry.

I agree with the author. Especially when he said "The more software continues to take over every aspect of our lives, the more important it will be for us to take a stand and ensure that our ethics are ever-present in our code." He mentioned how it's starting to integrate in so many aspects of society like AI programs that help doctors diagnose disease. I think we all need to take a step back and think what things in life can omit AI intervention. There is just certain aspects that need a moral compass that humans have in technological innovation that AI doesn't. What stuck out to me was one of the last lines of his article when is "I always try to think twice about the effects of my code before I write it. I hope that you will too." I will be taking that with me into the future.


> [Self Driving Car Ethics](https://www.freep.com/story/money/cars/2017/11/21/self-driving-cars-ethics/804805001/)

The article dives into the ethical complexities inherent in the development and deployment of self-driving vehicles. There is a moral dilemma faced by programmers and policymakers when programming these vehicles to make split-second life-or-death decisions. The "trolley problem" analogy shows the challenges of creating algorithms that prioritize lives in dangerous situations. There is a critical need for ethical frameworks to guide the behavior of AI, particularly in scenarios where human lives are at stake.

I agree with addressing the ethical considerations in AI technology. The scenarios presented, such as the choice between hitting a pedestrian or swerving into oncoming traffic, it just seems like such a dire situation that only a human can process the ethical dilemma. Self-driving cars are forcing us to confront age-old ethical questions in a modern context. The discussion around whether vehicles should prioritize the safety of passengers or minimize overall harm to all involved parties raises moral and philosophical consideration that I think are too complex and too human for AI to comprehend. But at the same time it's wild that a human said “If it happens where there is a situation where a car couldn’t escape, it’ll go for the smaller thing.” and the author asked what if the smaller thing was a child. At the end of the day even if its humans coding them there needs to be interdisciplinary collaboration between developers, ethicists, policymakers, and the public to navigate these complex ethical landscapes.
